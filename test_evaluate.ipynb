{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bae298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from mecab import MeCab\n",
    "\n",
    "mecab = MeCab()\n",
    "\n",
    "def get_top_n_structure_similar(df, target_sentence, n=15):\n",
    "    # \"msg\" 컬럼(문장 리스트) → 품사 시퀀스 변환\n",
    "    \n",
    "    err_sentence_list = df[\"err_sentence\"].tolist()\n",
    "    sentence_list = df[\"cor_sentence\"].tolist()\n",
    "    sentence_list_pos = [\" \".join([tag for _, tag in mecab.pos(s)]) for s in sentence_list]\n",
    "    target_pos = \" \".join([tag for _, tag in mecab.pos(target_sentence)])\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform([target_pos] + sentence_list_pos)\n",
    "    sims = cosine_similarity(X[0], X[1:])[0]\n",
    "    \n",
    "    top_idxs = sims.argsort()[::-1][:n]\n",
    "    # 결과를 (원문, 유사도) 튜플로 반환\n",
    "    #return [err_sentence_list[idx] for idx in top_idxs], [(sentence_list[idx], sims[idx]) for idx in top_idxs]\n",
    "    return list(zip([err_sentence_list[idx] for idx in top_idxs], [sentence_list[idx] for idx in top_idxs]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102c88ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv('data/train_dataset.csv')\n",
    "\n",
    "print(get_top_n_structure_similar(df, \"칭찬을 받으니 부끄럽자 얼굴이 빨개졌다.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85b7a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from prompts import baseline_prompt\n",
    "import promptTemplate\n",
    "import re\n",
    "import importlib\n",
    "\n",
    "\n",
    "importlib.reload(promptTemplate)\n",
    "\n",
    "def extract_answer(text):\n",
    "    # [Answer]: 뒤에 오는 줄의 맨 앞~줄 끝까지 추출\n",
    "    match = re.search(r\"\\[Answer\\]:\\s*(.*)\", text)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    args = {\"input\":\"data/train_dataset.csv\",\"model\":\"solar-pro2\",\"output\":\"eval_submission.csv\"}\n",
    "    \n",
    "\n",
    "    # Load environment variables\n",
    "    load_dotenv()\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv(args['input'])\n",
    "    \n",
    "    if \"err_sentence\" not in df.columns:\n",
    "        raise ValueError(\"Input CSV must contain 'err_sentence' column\")\n",
    "\n",
    "    # Setup Upstage client\n",
    "    api_key = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"UPSTAGE_API_KEY not found in environment variables\")\n",
    "    \n",
    "    print(f\"Model: {args['model']}\")\n",
    "    print(f\"Output: {args['output']}\")\n",
    "\n",
    "    err_sentences = []\n",
    "    cor_sentences = []\n",
    "    \n",
    "    # Process each sentence\n",
    "    for row in tqdm(df.itertuples(), total=len(df), desc=\"Generating\"):\n",
    "\n",
    "        text = row.err_sentence\n",
    "        \n",
    "        err_sentences.append(text)\n",
    "\n",
    "        examples = get_top_n_structure_similar(df, text)\n",
    "        \n",
    "        try:\n",
    "            resp = promptTemplate.process(text, examples[1:])\n",
    "            corrected = extract_answer(resp)\n",
    "            cor_sentences.append(corrected)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing: {text[:50]}... - {e}\")\n",
    "            cor_sentences.append(text)  # fallback to original\n",
    "\n",
    "    # Save results with required column names\n",
    "    out_df = pd.DataFrame({\"err_sentence\": err_sentences, \"cor_sentence\": cor_sentences})\n",
    "    out_df.to_csv(args['output'], index=False)\n",
    "    print(f\"Wrote {len(out_df)} rows to {args['output']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1250fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "   \n",
    "    main()\n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "    # 명령어 실행 및 콘솔 출력\n",
    "    cmd = \"uv run python evaluate.py --true_df data/train_dataset.csv --pred_df eval_submission.csv --output analysis.csv\"\n",
    "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    print(\"콘솔 출력:\")\n",
    "    print(result.stdout)\n",
    "\n",
    "    # 파일 결과 확인\n",
    "    df = pd.read_csv(\"analysis.csv\")\n",
    "    print(\"analysis.csv 결과:\")\n",
    "    print(df)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompthon-baseline (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
